{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# M\u00f3dulo 1: Introducci\u00f3n a la Miner\u00eda de Datos",
        "## Validaci\u00f3n y Evaluaci\u00f3n de Modelos",
        "",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/husseinlopez/diplomadoIA/blob/main/M1-6_Ejercicios_Validacion.ipynb)",
        "",
        "**Diplomado en Inteligencia Artificial**  ",
        "**Dr. Irvin Hussein L\u00f3pez Nava**  ",
        "**CICESE - UABC**",
        "",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos de esta sesi\u00f3n",
        "",
        "1. **Comprender la importancia de la partici\u00f3n de datos** para evaluar generalizaci\u00f3n",
        "2. **Implementar diferentes esquemas de validaci\u00f3n**: Hold-out, k-Fold CV, Leave-One-Out",
        "3. **Aplicar m\u00e9tricas de regresi\u00f3n**: MAE, MSE, RMSE, R\u00b2",
        "4. **Aplicar m\u00e9tricas de clasificaci\u00f3n**: Accuracy, Precision, Recall, F1, ROC-AUC, MCC",
        "5. **Evitar data leakage** en el pipeline de evaluaci\u00f3n",
        "6. **Interpretar resultados** considerando sesgo y varianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estructura del notebook",
        "",
        "### Parte 1: Esquemas de Partici\u00f3n y Validaci\u00f3n",
        "* Hold-out simple",
        "* k-Fold Cross-Validation",
        "* Leave-One-Out Cross-Validation",
        "* Estratificaci\u00f3n",
        "",
        "### Parte 2: Evaluaci\u00f3n de Modelos de Regresi\u00f3n",
        "* M\u00e9tricas: MAE, MSE, RMSE, R\u00b2",
        "* Comparaci\u00f3n de modelos",
        "* An\u00e1lisis de residuos",
        "",
        "### Parte 3: Evaluaci\u00f3n de Modelos de Clasificaci\u00f3n",
        "* Matriz de confusi\u00f3n",
        "* M\u00e9tricas: Accuracy, Precision, Recall, F1",
        "* Curva ROC y AUC",
        "* Matthews Correlation Coefficient (MCC)",
        "",
        "### Parte 4: Comparaci\u00f3n de Modelos y Mejores Pr\u00e1cticas",
        "* Variabilidad del desempe\u00f1o",
        "* Data leakage (c\u00f3mo evitarlo)",
        "* Selecci\u00f3n de m\u00e9tricas seg\u00fan contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "## 0. Configuraci\u00f3n del Entorno",
        "",
        "Importaremos las bibliotecas necesarias para validaci\u00f3n y evaluaci\u00f3n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manejo de datos",
        "import numpy as np",
        "import pandas as pd",
        "from scipy import stats",
        "",
        "# Visualizaci\u00f3n",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "import plotly.graph_objects as go",
        "from plotly.subplots import make_subplots",
        "",
        "# Configuraci\u00f3n de visualizaci\u00f3n",
        "plt.style.use('seaborn-v0_8-darkgrid')",
        "sns.set_palette(\"husl\")",
        "%matplotlib inline",
        "",
        "# Reproducibilidad",
        "np.random.seed(42)",
        "",
        "# Ignorar warnings",
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "print(\"\u2713 Bibliotecas b\u00e1sicas importadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Machine Learning",
        "from sklearn.model_selection import (",
        "    train_test_split, ",
        "    cross_val_score, ",
        "    cross_validate,",
        "    KFold, ",
        "    StratifiedKFold, ",
        "    LeaveOneOut",
        ")",
        "",
        "# Modelos",
        "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier",
        "from sklearn.svm import SVR, SVC",
        "",
        "# Preprocesamiento",
        "from sklearn.preprocessing import StandardScaler",
        "from sklearn.pipeline import Pipeline",
        "",
        "# M\u00e9tricas de regresi\u00f3n",
        "from sklearn.metrics import (",
        "    mean_absolute_error,",
        "    mean_squared_error,",
        "    r2_score",
        ")",
        "",
        "# M\u00e9tricas de clasificaci\u00f3n",
        "from sklearn.metrics import (",
        "    accuracy_score,",
        "    precision_score,",
        "    recall_score,",
        "    f1_score,",
        "    confusion_matrix,",
        "    classification_report,",
        "    roc_curve,",
        "    roc_auc_score,",
        "    matthews_corrcoef",
        ")",
        "",
        "# Datasets",
        "from sklearn.datasets import (",
        "    load_diabetes,",
        "    load_breast_cancer,",
        "    make_classification,",
        "    make_regression",
        ")",
        "",
        "print(\"\u2713 Bibliotecas de ML importadas correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "# Parte 1: Esquemas de Partici\u00f3n y Validaci\u00f3n",
        "",
        "La partici\u00f3n de datos es fundamental para estimar la capacidad de generalizaci\u00f3n del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 \u00bfPor qu\u00e9 particionar los datos?",
        "",
        "**Problema fundamental**:",
        "- El modelo se ajusta minimizando el error en los datos de entrenamiento",
        "- Si evaluamos en los mismos datos, el error ser\u00e1 **optimista**",
        "- No sabremos si el modelo **generaliza** a datos nuevos",
        "",
        "**Soluci\u00f3n**:",
        "- Separar datos en **entrenamiento** y **prueba**",
        "- Entrenar solo con training",
        "- Evaluar solo con test (datos \"no vistos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Hold-Out Simple",
        "",
        "La estrategia m\u00e1s b\u00e1sica: una sola partici\u00f3n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset sint\u00e9tico para regresi\u00f3n",
        "np.random.seed(42)",
        "X_reg, y_reg = make_regression(",
        "    n_samples=200, ",
        "    n_features=10, ",
        "    n_informative=8,",
        "    noise=10, ",
        "    random_state=42",
        ")",
        "",
        "print(\"=\"*80)",
        "print(\"HOLD-OUT SIMPLE\")",
        "print(\"=\"*80)",
        "",
        "# Partici\u00f3n 70-30",
        "X_train, X_test, y_train, y_test = train_test_split(",
        "    X_reg, y_reg, ",
        "    test_size=0.3, ",
        "    random_state=42",
        ")",
        "",
        "print(f\"\\nTotal de datos: {len(X_reg)}\")",
        "print(f\"  Training: {len(X_train)} ({100*len(X_train)/len(X_reg):.0f}%)\")",
        "print(f\"  Test: {len(X_test)} ({100*len(X_test)/len(X_reg):.0f}%)\")",
        "",
        "# Entrenar modelo simple",
        "model = LinearRegression()",
        "model.fit(X_train, y_train)",
        "",
        "# Predecir",
        "y_train_pred = model.predict(X_train)",
        "y_test_pred = model.predict(X_test)",
        "",
        "# Calcular errores",
        "train_mse = mean_squared_error(y_train, y_train_pred)",
        "test_mse = mean_squared_error(y_test, y_test_pred)",
        "train_r2 = r2_score(y_train, y_train_pred)",
        "test_r2 = r2_score(y_test, y_test_pred)",
        "",
        "print(f\"\\nResultados:\")",
        "print(f\"  MSE Training: {train_mse:.2f}\")",
        "print(f\"  MSE Test: {test_mse:.2f}\")",
        "print(f\"  R\u00b2 Training: {train_r2:.3f}\")",
        "print(f\"  R\u00b2 Test: {test_r2:.3f}\")",
        "",
        "print(f\"\\n\u26a0\ufe0f  Limitaci\u00f3n: El resultado depende de la partici\u00f3n espec\u00edfica\")",
        "print(f\"   Cambiar random_state da resultados diferentes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variabilidad del Hold-Out",
        "",
        "Veamos c\u00f3mo cambia el desempe\u00f1o con diferentes particiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejecutar hold-out con diferentes semillas",
        "results = []",
        "",
        "for seed in range(30):",
        "    X_train, X_test, y_train, y_test = train_test_split(",
        "        X_reg, y_reg, test_size=0.3, random_state=seed",
        "    )",
        "    ",
        "    model = LinearRegression()",
        "    model.fit(X_train, y_train)",
        "    y_pred = model.predict(X_test)",
        "    ",
        "    mse = mean_squared_error(y_test, y_pred)",
        "    r2 = r2_score(y_test, y_pred)",
        "    ",
        "    results.append({'seed': seed, 'MSE': mse, 'R\u00b2': r2})",
        "",
        "df_results = pd.DataFrame(results)",
        "",
        "# Visualizaci\u00f3n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))",
        "",
        "# MSE",
        "ax = axes[0]",
        "ax.hist(df_results['MSE'], bins=15, alpha=0.7, color='steelblue', edgecolor='black')",
        "ax.axvline(df_results['MSE'].mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {df_results[\"MSE\"].mean():.2f}')",
        "ax.set_xlabel('MSE en Test')",
        "ax.set_ylabel('Frecuencia')",
        "ax.set_title('Variabilidad del MSE\\n(30 particiones diferentes)', fontweight='bold')",
        "ax.legend()",
        "ax.grid(alpha=0.3)",
        "",
        "# R\u00b2",
        "ax = axes[1]",
        "ax.hist(df_results['R\u00b2'], bins=15, alpha=0.7, color='green', edgecolor='black')",
        "ax.axvline(df_results['R\u00b2'].mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {df_results[\"R\u00b2\"].mean():.3f}')",
        "ax.set_xlabel('R\u00b2 en Test')",
        "ax.set_ylabel('Frecuencia')",
        "ax.set_title('Variabilidad del R\u00b2\\n(30 particiones diferentes)', fontweight='bold')",
        "ax.legend()",
        "ax.grid(alpha=0.3)",
        "",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"MSE: \u03bc = {df_results['MSE'].mean():.2f}, \u03c3 = {df_results['MSE'].std():.2f}\")",
        "print(f\"R\u00b2:  \u03bc = {df_results['R\u00b2'].mean():.3f}, \u03c3 = {df_results['R\u00b2'].std():.3f}\")",
        "print(f\"\\n\ud83d\udca1 Varianza alta \u2192 Hold-out simple no es confiable\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 k-Fold Cross-Validation",
        "",
        "Reduce la varianza dividiendo los datos en k subconjuntos (folds)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# k-Fold CV con k=5",
        "print(\"=\"*80)",
        "print(\"K-FOLD CROSS-VALIDATION (k=5)\")",
        "print(\"=\"*80)",
        "",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)",
        "",
        "model = LinearRegression()",
        "",
        "# cross_validate devuelve m\u00faltiples m\u00e9tricas",
        "cv_results = cross_validate(",
        "    model, X_reg, y_reg,",
        "    cv=kfold,",
        "    scoring=['neg_mean_squared_error', 'r2'],",
        "    return_train_score=True",
        ")",
        "",
        "# Convertir a positivo (sklearn usa negative MSE)",
        "train_mse = -cv_results['train_neg_mean_squared_error']",
        "test_mse = -cv_results['test_neg_mean_squared_error']",
        "train_r2 = cv_results['train_r2']",
        "test_r2 = cv_results['test_r2']",
        "",
        "print(f\"\\nResultados por fold:\")",
        "print(f\"{'Fold':<10} {'Train MSE':<15} {'Test MSE':<15} {'Train R\u00b2':<15} {'Test R\u00b2':<15}\")",
        "print(\"-\" * 70)",
        "for i in range(5):",
        "    print(f\"{i+1:<10} {train_mse[i]:<15.2f} {test_mse[i]:<15.2f} {train_r2[i]:<15.3f} {test_r2[i]:<15.3f}\")",
        "",
        "print(\"\\nEstad\u00edsticas agregadas:\")",
        "print(f\"  Test MSE: {test_mse.mean():.2f} \u00b1 {test_mse.std():.2f}\")",
        "print(f\"  Test R\u00b2:  {test_r2.mean():.3f} \u00b1 {test_r2.std():.3f}\")",
        "",
        "print(f\"\\n\u2713 Cada observaci\u00f3n se usa para entrenamiento y prueba\")",
        "print(f\"\u2713 Estimaci\u00f3n m\u00e1s estable que hold-out simple\")",
        "",
        "# Visualizaci\u00f3n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))",
        "",
        "# MSE por fold",
        "ax = axes[0]",
        "x = np.arange(1, 6)",
        "ax.bar(x - 0.2, train_mse, width=0.4, label='Training', alpha=0.7, color='steelblue')",
        "ax.bar(x + 0.2, test_mse, width=0.4, label='Test', alpha=0.7, color='orange')",
        "ax.axhline(test_mse.mean(), color='red', linestyle='--', linewidth=2, label=f'Test \u03bc={test_mse.mean():.2f}')",
        "ax.set_xlabel('Fold')",
        "ax.set_ylabel('MSE')",
        "ax.set_title('MSE por Fold (5-Fold CV)', fontweight='bold')",
        "ax.set_xticks(x)",
        "ax.legend()",
        "ax.grid(alpha=0.3, axis='y')",
        "",
        "# R\u00b2 por fold",
        "ax = axes[1]",
        "ax.bar(x - 0.2, train_r2, width=0.4, label='Training', alpha=0.7, color='steelblue')",
        "ax.bar(x + 0.2, test_r2, width=0.4, label='Test', alpha=0.7, color='orange')",
        "ax.axhline(test_r2.mean(), color='red', linestyle='--', linewidth=2, label=f'Test \u03bc={test_r2.mean():.3f}')",
        "ax.set_xlabel('Fold')",
        "ax.set_ylabel('R\u00b2')",
        "ax.set_title('R\u00b2 por Fold (5-Fold CV)', fontweight='bold')",
        "ax.set_xticks(x)",
        "ax.legend()",
        "ax.grid(alpha=0.3, axis='y')",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 Leave-One-Out Cross-Validation (LOOCV)",
        "",
        "Caso extremo donde k = n (cada observaci\u00f3n es un fold)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOOCV (solo con subset peque\u00f1o por costo computacional)",
        "print(\"=\"*80)",
        "print(\"LEAVE-ONE-OUT CROSS-VALIDATION\")",
        "print(\"=\"*80)",
        "",
        "# Usar solo primeras 100 observaciones para estabilidad",
        "X_small = X_reg[:100]",
        "y_small = y_reg[:100]",
        "",
        "loo = LeaveOneOut()",
        "",
        "# Usar modelo m\u00e1s robusto para LOOCV",
        "model = Ridge(alpha=1.0)",
        "",
        "# LOOCV con manejo de errores",
        "try:",
        "    scores = cross_val_score(model, X_small, y_small, cv=loo, scoring='r2')",
        "    ",
        "    # Filtrar NaN si los hay",
        "    scores_valid = scores[~np.isnan(scores)]",
        "    ",
        "    if len(scores_valid) == 0:",
        "        print(f\"\\n\u26a0\ufe0f  Todos los scores son NaN. Usando MAE en su lugar...\")",
        "        scores = cross_val_score(model, X_small, y_small, cv=loo, scoring='neg_mean_absolute_error')",
        "        scores = -scores  # Convertir a positivo",
        "        metric_name = 'MAE'",
        "    else:",
        "        scores = scores_valid",
        "        metric_name = 'R\u00b2'",
        "    ",
        "    print(f\"\\nDatos: {len(X_small)} observaciones\")",
        "    print(f\"Iteraciones: {loo.get_n_splits(X_small)} (una por observaci\u00f3n)\")",
        "    print(f\"\\n{metric_name} por observaci\u00f3n:\")",
        "    print(f\"  Media: {scores.mean():.3f}\")",
        "    print(f\"  Std: {scores.std():.3f}\")",
        "    print(f\"  Min: {scores.min():.3f}\")",
        "    print(f\"  Max: {scores.max():.3f}\")",
        "    ",
        "    print(f\"\\n\u26a0\ufe0f  LOOCV:\")",
        "    print(f\"   \u2713 Bajo sesgo (entrena con n-1 datos)\")",
        "    print(f\"   \u2717 Alta varianza\")",
        "    print(f\"   \u2717 Alto costo computacional (n iteraciones)\")",
        "    print(f\"   \u2192 Usar solo con datasets peque\u00f1os\")",
        "    ",
        "    # Visualizaci\u00f3n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))",
        "    ax.hist(scores, bins=20, alpha=0.7, color='purple', edgecolor='black')",
        "    ax.axvline(scores.mean(), color='red', linestyle='--', linewidth=2, ",
        "              label=f'Media: {scores.mean():.3f}')",
        "    ax.set_xlabel(f'{metric_name} Score')",
        "    ax.set_ylabel('Frecuencia')",
        "    ax.set_title(f'Distribuci\u00f3n de {metric_name} en LOOCV\\n({len(scores)} iteraciones)', ",
        "                fontweight='bold')",
        "    ax.legend()",
        "    ax.grid(alpha=0.3)",
        "    plt.tight_layout()",
        "    plt.show()",
        "    ",
        "except Exception as e:",
        "    print(f\"\\n\u26a0\ufe0f  Error en LOOCV: {str(e)}\")",
        "    print(f\"\\nLOOCV puede ser inestable con pocos datos y regresi\u00f3n lineal.\")",
        "    print(f\"En la pr\u00e1ctica, k-Fold CV (k=5 o k=10) es m\u00e1s robusto.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 Estratificaci\u00f3n en Clasificaci\u00f3n",
        "",
        "Preservar proporciones de clase en cada fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dataset desbalanceado para clasificaci\u00f3n",
        "X_class, y_class = make_classification(",
        "    n_samples=200,",
        "    n_features=10,",
        "    n_informative=8,",
        "    n_classes=2,",
        "    weights=[0.7, 0.3],  # 70% clase 0, 30% clase 1",
        "    random_state=42",
        ")",
        "",
        "print(\"=\"*80)",
        "print(\"ESTRATIFICACI\u00d3N EN CLASIFICACI\u00d3N\")",
        "print(\"=\"*80)",
        "",
        "print(f\"\\nDistribuci\u00f3n original:\")",
        "unique, counts = np.unique(y_class, return_counts=True)",
        "for cls, count in zip(unique, counts):",
        "    print(f\"  Clase {cls}: {count} ({100*count/len(y_class):.1f}%)\")",
        "",
        "# CV SIN estratificaci\u00f3n",
        "print(f\"\\n--- K-Fold CV SIN estratificaci\u00f3n ---\")",
        "kfold_no_strat = KFold(n_splits=5, shuffle=True, random_state=42)",
        "",
        "for i, (train_idx, test_idx) in enumerate(kfold_no_strat.split(X_class), 1):",
        "    y_test_fold = y_class[test_idx]",
        "    class_1_pct = 100 * (y_test_fold == 1).sum() / len(y_test_fold)",
        "    print(f\"  Fold {i}: {class_1_pct:.1f}% clase 1 en test\")",
        "",
        "# CV CON estratificaci\u00f3n",
        "print(f\"\\n--- K-Fold CV CON estratificaci\u00f3n ---\")",
        "kfold_strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)",
        "",
        "for i, (train_idx, test_idx) in enumerate(kfold_strat.split(X_class, y_class), 1):",
        "    y_test_fold = y_class[test_idx]",
        "    class_1_pct = 100 * (y_test_fold == 1).sum() / len(y_test_fold)",
        "    print(f\"  Fold {i}: {class_1_pct:.1f}% clase 1 en test\")",
        "",
        "print(f\"\\n\u2713 Estratificaci\u00f3n preserva las proporciones originales\")",
        "print(f\"\u2713 Esencial con clases desbalanceadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "# Parte 2: Evaluaci\u00f3n de Modelos de Regresi\u00f3n",
        "",
        "M\u00e9tricas para problemas donde la variable objetivo es continua."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Dataset: Diabetes",
        "",
        "Usaremos el dataset cl\u00e1sico de diabetes para predecir progresi\u00f3n de la enfermedad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset",
        "diabetes = load_diabetes()",
        "X_diabetes = diabetes.data",
        "y_diabetes = diabetes.target",
        "",
        "print(\"=\"*80)",
        "print(\"DATASET: Diabetes\")",
        "print(\"=\"*80)",
        "print(f\"\\nObservaciones: {X_diabetes.shape[0]}\")",
        "print(f\"Features: {X_diabetes.shape[1]}\")",
        "print(f\"\\nVariable objetivo: Progresi\u00f3n de diabetes (continua)\")",
        "print(f\"  Min: {y_diabetes.min():.1f}\")",
        "print(f\"  Max: {y_diabetes.max():.1f}\")",
        "print(f\"  Media: {y_diabetes.mean():.1f}\")",
        "print(f\"  Std: {y_diabetes.std():.1f}\")",
        "",
        "# Partici\u00f3n",
        "X_train_diab, X_test_diab, y_train_diab, y_test_diab = train_test_split(",
        "    X_diabetes, y_diabetes, test_size=0.3, random_state=42",
        ")",
        "",
        "print(f\"\\nPartici\u00f3n 70-30:\")",
        "print(f\"  Training: {len(X_train_diab)}\")",
        "print(f\"  Test: {len(X_test_diab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 M\u00e9tricas de Regresi\u00f3n",
        "",
        "Compararemos MAE, MSE, RMSE y R\u00b2 en diferentes modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_regression_model(model, X_train, X_test, y_train, y_test, model_name):",
        "    \"\"\"",
        "    Eval\u00faa un modelo de regresi\u00f3n con m\u00faltiples m\u00e9tricas",
        "    \"\"\"",
        "    # Entrenar",
        "    model.fit(X_train, y_train)",
        "    ",
        "    # Predecir",
        "    y_train_pred = model.predict(X_train)",
        "    y_test_pred = model.predict(X_test)",
        "    ",
        "    # Calcular m\u00e9tricas",
        "    metrics = {",
        "        'Model': model_name,",
        "        'Train MAE': mean_absolute_error(y_train, y_train_pred),",
        "        'Test MAE': mean_absolute_error(y_test, y_test_pred),",
        "        'Train MSE': mean_squared_error(y_train, y_train_pred),",
        "        'Test MSE': mean_squared_error(y_test, y_test_pred),",
        "        'Train RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),",
        "        'Test RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),",
        "        'Train R\u00b2': r2_score(y_train, y_train_pred),",
        "        'Test R\u00b2': r2_score(y_test, y_test_pred)",
        "    }",
        "    ",
        "    return metrics, y_test_pred",
        "",
        "# Modelos a comparar",
        "models = {",
        "    'Linear Regression': LinearRegression(),",
        "    'Ridge (\u03b1=1.0)': Ridge(alpha=1.0),",
        "    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=42),",
        "    'Random Forest': RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42),",
        "    'KNN (k=5)': KNeighborsRegressor(n_neighbors=5)",
        "}",
        "",
        "results = []",
        "predictions = {}",
        "",
        "print(\"=\"*80)",
        "print(\"COMPARACI\u00d3N DE MODELOS - REGRESI\u00d3N\")",
        "print(\"=\"*80)",
        "",
        "for name, model in models.items():",
        "    metrics, y_pred = evaluate_regression_model(",
        "        model, X_train_diab, X_test_diab, y_train_diab, y_test_diab, name",
        "    )",
        "    results.append(metrics)",
        "    predictions[name] = y_pred",
        "    print(f\"\u2713 {name}\")",
        "",
        "df_results_reg = pd.DataFrame(results)",
        "print(f\"\\n{df_results_reg.to_string(index=False)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizaci\u00f3n de Resultados",
        "",
        "Comparemos las m\u00e9tricas y las predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaci\u00f3n de m\u00e9tricas",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))",
        "",
        "metrics_to_plot = [",
        "    ('Test MAE', 'MAE en Test', 'steelblue'),",
        "    ('Test RMSE', 'RMSE en Test', 'orange'),",
        "    ('Test R\u00b2', 'R\u00b2 en Test', 'green'),",
        "]",
        "",
        "for idx, (metric, title, color) in enumerate(metrics_to_plot):",
        "    ax = axes[idx // 2, idx % 2]",
        "    ",
        "    values = df_results_reg[metric].values",
        "    models_names = df_results_reg['Model'].values",
        "    ",
        "    bars = ax.barh(models_names, values, color=color, alpha=0.7, edgecolor='black')",
        "    ax.set_xlabel(metric, fontsize=11)",
        "    ax.set_title(title, fontweight='bold', fontsize=13)",
        "    ax.grid(alpha=0.3, axis='x')",
        "    ",
        "    # A\u00f1adir valores",
        "    for bar, val in zip(bars, values):",
        "        width = bar.get_width()",
        "        ax.text(width, bar.get_y() + bar.get_height()/2,",
        "               f' {val:.2f}', ha='left', va='center', fontsize=10, fontweight='bold')",
        "",
        "# Predicciones vs Real (mejor modelo por R\u00b2)",
        "ax = axes[1, 1]",
        "best_model_name = df_results_reg.loc[df_results_reg['Test R\u00b2'].idxmax(), 'Model']",
        "y_pred_best = predictions[best_model_name]",
        "",
        "ax.scatter(y_test_diab, y_pred_best, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)",
        "ax.plot([y_test_diab.min(), y_test_diab.max()], ",
        "        [y_test_diab.min(), y_test_diab.max()], ",
        "        'r--', linewidth=2, label='Predicci\u00f3n perfecta')",
        "ax.set_xlabel('Valores Reales', fontsize=11)",
        "ax.set_ylabel('Valores Predichos', fontsize=11)",
        "ax.set_title(f'Predicciones vs Reales\\n(Mejor modelo: {best_model_name})', fontweight='bold', fontsize=13)",
        "ax.legend()",
        "ax.grid(alpha=0.3)",
        "",
        "plt.suptitle('Comparaci\u00f3n de Modelos de Regresi\u00f3n', fontsize=16, fontweight='bold')",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"\\n\ud83c\udfc6 Mejor modelo por R\u00b2: {best_model_name}\")",
        "print(f\"   Test R\u00b2: {df_results_reg.loc[df_results_reg['Test R\u00b2'].idxmax(), 'Test R\u00b2']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 An\u00e1lisis de Residuos",
        "",
        "Los residuos revelan patrones de error del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An\u00e1lisis de residuos del mejor modelo",
        "best_model_idx = df_results_reg['Test R\u00b2'].idxmax()",
        "best_model_name = df_results_reg.loc[best_model_idx, 'Model']",
        "y_pred_best = predictions[best_model_name]",
        "",
        "residuals = y_test_diab - y_pred_best",
        "",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))",
        "",
        "# Distribuci\u00f3n de residuos",
        "ax = axes[0]",
        "ax.hist(residuals, bins=20, alpha=0.7, color='steelblue', edgecolor='black')",
        "ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Cero')",
        "ax.axvline(residuals.mean(), color='orange', linestyle='--', linewidth=2, label=f'Media: {residuals.mean():.2f}')",
        "ax.set_xlabel('Residuos')",
        "ax.set_ylabel('Frecuencia')",
        "ax.set_title('Distribuci\u00f3n de Residuos', fontweight='bold')",
        "ax.legend()",
        "ax.grid(alpha=0.3)",
        "",
        "# Residuos vs Predicciones",
        "ax = axes[1]",
        "ax.scatter(y_pred_best, residuals, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)",
        "ax.axhline(0, color='red', linestyle='--', linewidth=2)",
        "ax.set_xlabel('Valores Predichos')",
        "ax.set_ylabel('Residuos')",
        "ax.set_title('Residuos vs Predicciones', fontweight='bold')",
        "ax.grid(alpha=0.3)",
        "",
        "# Q-Q plot",
        "ax = axes[2]",
        "stats.probplot(residuals, dist=\"norm\", plot=ax)",
        "ax.set_title('Q-Q Plot (normalidad de residuos)', fontweight='bold')",
        "ax.grid(alpha=0.3)",
        "",
        "plt.suptitle(f'An\u00e1lisis de Residuos: {best_model_name}', fontsize=16, fontweight='bold')",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"Estad\u00edsticas de residuos:\")",
        "print(f\"  Media: {residuals.mean():.2f} (debe estar cerca de 0)\")",
        "print(f\"  Std: {residuals.std():.2f}\")",
        "print(f\"  Min: {residuals.min():.2f}\")",
        "print(f\"  Max: {residuals.max():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "# Parte 3: Evaluaci\u00f3n de Modelos de Clasificaci\u00f3n",
        "",
        "M\u00e9tricas para problemas donde la variable objetivo es categ\u00f3rica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Dataset: Breast Cancer",
        "",
        "Usaremos el dataset Wisconsin Breast Cancer (clasificaci\u00f3n binaria)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset",
        "cancer = load_breast_cancer()",
        "X_cancer = cancer.data",
        "y_cancer = cancer.target",
        "",
        "print(\"=\"*80)",
        "print(\"DATASET: Wisconsin Breast Cancer\")",
        "print(\"=\"*80)",
        "print(f\"\\nObservaciones: {X_cancer.shape[0]}\")",
        "print(f\"Features: {X_cancer.shape[1]}\")",
        "print(f\"\\nClases:\")",
        "unique, counts = np.unique(y_cancer, return_counts=True)",
        "for cls, count, name in zip(unique, counts, cancer.target_names):",
        "    print(f\"  {cls} ({name}): {count} ({100*count/len(y_cancer):.1f}%)\")",
        "",
        "# Partici\u00f3n estratificada",
        "X_train_canc, X_test_canc, y_train_canc, y_test_canc = train_test_split(",
        "    X_cancer, y_cancer, test_size=0.3, random_state=42, stratify=y_cancer",
        ")",
        "",
        "print(f\"\\nPartici\u00f3n estratificada 70-30:\")",
        "print(f\"  Training: {len(X_train_canc)}\")",
        "print(f\"  Test: {len(X_test_canc)}\")",
        "",
        "# Verificar estratificaci\u00f3n",
        "print(f\"\\nDistribuci\u00f3n en test:\")",
        "unique, counts = np.unique(y_test_canc, return_counts=True)",
        "for cls, count in zip(unique, counts):",
        "    print(f\"  Clase {cls}: {count} ({100*count/len(y_test_canc):.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Matriz de Confusi\u00f3n",
        "",
        "La base para todas las m\u00e9tricas de clasificaci\u00f3n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, class_names, model_name):",
        "    \"\"\"",
        "    Visualiza la matriz de confusi\u00f3n",
        "    \"\"\"",
        "    cm = confusion_matrix(y_true, y_pred)",
        "    ",
        "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))",
        "    ",
        "    # Heatmap",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ",
        "                xticklabels=class_names, yticklabels=class_names,",
        "                cbar_kws={'label': 'Cuenta'}, ax=ax)",
        "    ",
        "    ax.set_ylabel('Clase Real', fontsize=12)",
        "    ax.set_xlabel('Clase Predicha', fontsize=12)",
        "    ax.set_title(f'Matriz de Confusi\u00f3n\\n{model_name}', fontweight='bold', fontsize=14)",
        "    ",
        "    # A\u00f1adir anotaciones TN, FP, FN, TP",
        "    tn, fp, fn, tp = cm.ravel()",
        "    annotations = [",
        "        (0, 0, f'TN={tn}'),",
        "        (1, 0, f'FP={fp}'),",
        "        (0, 1, f'FN={fn}'),",
        "        (1, 1, f'TP={tp}')",
        "    ]",
        "    ",
        "    for x, y, text in annotations:",
        "        ax.text(x + 0.5, y + 0.75, text, ha='center', va='center',",
        "               fontsize=10, color='darkred', fontweight='bold')",
        "    ",
        "    plt.tight_layout()",
        "    return fig, cm",
        "",
        "# Entrenar modelo simple",
        "model_lr = LogisticRegression(max_iter=10000, random_state=42)",
        "model_lr.fit(X_train_canc, y_train_canc)",
        "y_pred_lr = model_lr.predict(X_test_canc)",
        "",
        "# Matriz de confusi\u00f3n",
        "fig_cm, cm = plot_confusion_matrix(y_test_canc, y_pred_lr, cancer.target_names, 'Logistic Regression')",
        "plt.show()",
        "",
        "# M\u00e9tricas b\u00e1sicas",
        "tn, fp, fn, tp = cm.ravel()",
        "print(\"=\"*80)",
        "print(\"M\u00c9TRICAS DESDE LA MATRIZ DE CONFUSI\u00d3N\")",
        "print(\"=\"*80)",
        "print(f\"\\nVerdaderos Negativos (TN): {tn}\")",
        "print(f\"Falsos Positivos (FP):     {fp}  \u2190 Error Tipo I\")",
        "print(f\"Falsos Negativos (FN):     {fn}  \u2190 Error Tipo II\")",
        "print(f\"Verdaderos Positivos (TP): {tp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 M\u00e9tricas de Clasificaci\u00f3n",
        "",
        "Calculemos todas las m\u00e9tricas principales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_classification_metrics(y_true, y_pred, y_pred_proba=None):",
        "    \"\"\"",
        "    Calcula todas las m\u00e9tricas de clasificaci\u00f3n",
        "    \"\"\"",
        "    metrics = {",
        "        'Accuracy': accuracy_score(y_true, y_pred),",
        "        'Precision': precision_score(y_true, y_pred),",
        "        'Recall': recall_score(y_true, y_pred),",
        "        'F1-Score': f1_score(y_true, y_pred),",
        "        'MCC': matthews_corrcoef(y_true, y_pred)",
        "    }",
        "    ",
        "    if y_pred_proba is not None:",
        "        metrics['ROC-AUC'] = roc_auc_score(y_true, y_pred_proba)",
        "    ",
        "    return metrics",
        "",
        "# M\u00e9tricas para Logistic Regression",
        "y_pred_proba_lr = model_lr.predict_proba(X_test_canc)[:, 1]",
        "metrics_lr = calculate_classification_metrics(y_test_canc, y_pred_lr, y_pred_proba_lr)",
        "",
        "print(\"=\"*80)",
        "print(\"M\u00c9TRICAS DE CLASIFICACI\u00d3N - Logistic Regression\")",
        "print(\"=\"*80)",
        "",
        "for metric, value in metrics_lr.items():",
        "    print(f\"{metric:15s}: {value:.4f}\")",
        "",
        "print(f\"\\nInterpretaci\u00f3n:\")",
        "print(f\"  \u2022 Accuracy:  {metrics_lr['Accuracy']:.1%} de predicciones correctas\")",
        "print(f\"  \u2022 Precision: {metrics_lr['Precision']:.1%} de positivos predichos son correctos\")",
        "print(f\"  \u2022 Recall:    {metrics_lr['Recall']:.1%} de positivos reales fueron detectados\")",
        "print(f\"  \u2022 F1-Score:  Media arm\u00f3nica de Precision y Recall\")",
        "print(f\"  \u2022 MCC:       Correlaci\u00f3n entre predicci\u00f3n y realidad [-1, 1]\")",
        "print(f\"  \u2022 ROC-AUC:   \u00c1rea bajo la curva ROC [0.5, 1.0]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.4 Curva ROC y AUC",
        "",
        "La curva ROC eval\u00faa el desempe\u00f1o variando el umbral de clasificaci\u00f3n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Calcular curva ROC",
        "fpr, tpr, thresholds = roc_curve(y_test_canc, y_pred_proba_lr)",
        "roc_auc = roc_auc_score(y_test_canc, y_pred_proba_lr)",
        "",
        "# Visualizaci\u00f3n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))",
        "",
        "# Curva ROC",
        "ax = axes[0]",
        "ax.plot(fpr, tpr, linewidth=3, label=f'Logistic Regression (AUC = {roc_auc:.3f})', color='steelblue')",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Clasificador aleatorio (AUC = 0.5)', alpha=0.5)",
        "ax.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)",
        "ax.set_ylabel('True Positive Rate (Sensitivity)', fontsize=12)",
        "ax.set_title('Curva ROC', fontweight='bold', fontsize=14)",
        "ax.legend(fontsize=11)",
        "ax.grid(alpha=0.3)",
        "ax.set_xlim([-0.05, 1.05])",
        "ax.set_ylim([-0.05, 1.05])",
        "",
        "# Umbral \u00f3ptimo",
        "# Criterio: maximizar TPR - FPR",
        "optimal_idx = np.argmax(tpr - fpr)",
        "optimal_threshold = thresholds[optimal_idx]",
        "ax.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=10, ",
        "        label=f'Umbral \u00f3ptimo: {optimal_threshold:.3f}')",
        "ax.legend(fontsize=11)",
        "",
        "# Distribuci\u00f3n de probabilidades",
        "ax = axes[1]",
        "y_pred_proba_class0 = y_pred_proba_lr[y_test_canc == 0]",
        "y_pred_proba_class1 = y_pred_proba_lr[y_test_canc == 1]",
        "",
        "ax.hist(y_pred_proba_class0, bins=30, alpha=0.6, color='red', label='Clase 0 (Maligno)', edgecolor='black')",
        "ax.hist(y_pred_proba_class1, bins=30, alpha=0.6, color='green', label='Clase 1 (Benigno)', edgecolor='black')",
        "ax.axvline(0.5, color='black', linestyle='--', linewidth=2, label='Umbral por defecto: 0.5')",
        "ax.axvline(optimal_threshold, color='orange', linestyle='--', linewidth=2, label=f'Umbral \u00f3ptimo: {optimal_threshold:.3f}')",
        "ax.set_xlabel('Probabilidad predicha (clase 1)', fontsize=12)",
        "ax.set_ylabel('Frecuencia', fontsize=12)",
        "ax.set_title('Distribuci\u00f3n de Probabilidades Predichas', fontweight='bold', fontsize=14)",
        "ax.legend(fontsize=10)",
        "ax.grid(alpha=0.3)",
        "",
        "plt.suptitle('An\u00e1lisis ROC y Probabilidades', fontsize=16, fontweight='bold')",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")",
        "print(f\"Interpretaci\u00f3n: Probabilidad de que el modelo asigne mayor score a un\")",
        "print(f\"                positivo real que a un negativo real\")",
        "print(f\"\\nUmbral \u00f3ptimo: {optimal_threshold:.3f} (vs 0.5 por defecto)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5 Comparaci\u00f3n de M\u00faltiples Modelos",
        "",
        "Evaluemos diferentes clasificadores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def evaluate_classifier(model, X_train, X_test, y_train, y_test, model_name):",
        "    \"\"\"",
        "    Eval\u00faa un modelo de clasificaci\u00f3n con todas las m\u00e9tricas",
        "    \"\"\"",
        "    # Entrenar",
        "    model.fit(X_train, y_train)",
        "    ",
        "    # Predecir",
        "    y_pred = model.predict(X_test)",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None",
        "    ",
        "    # M\u00e9tricas",
        "    metrics = {",
        "        'Model': model_name,",
        "        'Accuracy': accuracy_score(y_test, y_pred),",
        "        'Precision': precision_score(y_test, y_pred),",
        "        'Recall': recall_score(y_test, y_pred),",
        "        'F1-Score': f1_score(y_test, y_pred),",
        "        'MCC': matthews_corrcoef(y_test, y_pred)",
        "    }",
        "    ",
        "    if y_pred_proba is not None:",
        "        metrics['ROC-AUC'] = roc_auc_score(y_test, y_pred_proba)",
        "    else:",
        "        metrics['ROC-AUC'] = np.nan",
        "    ",
        "    return metrics, y_pred, y_pred_proba",
        "",
        "# Modelos a comparar",
        "classifiers = {",
        "    'Logistic Regression': LogisticRegression(max_iter=10000, random_state=42),",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),",
        "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),",
        "    'SVM (linear)': SVC(kernel='linear', probability=True, random_state=42)",
        "}",
        "",
        "results_class = []",
        "predictions_class = {}",
        "probas_class = {}",
        "",
        "print(\"=\"*80)",
        "print(\"COMPARACI\u00d3N DE CLASIFICADORES\")",
        "print(\"=\"*80)",
        "",
        "for name, model in classifiers.items():",
        "    metrics, y_pred, y_proba = evaluate_classifier(",
        "        model, X_train_canc, X_test_canc, y_train_canc, y_test_canc, name",
        "    )",
        "    results_class.append(metrics)",
        "    predictions_class[name] = y_pred",
        "    probas_class[name] = y_proba",
        "    print(f\"\u2713 {name}\")",
        "",
        "df_results_class = pd.DataFrame(results_class)",
        "print(f\"\\n{df_results_class.to_string(index=False)}\")",
        "",
        "# Identificar mejor modelo",
        "best_f1_idx = df_results_class['F1-Score'].idxmax()",
        "best_model_name = df_results_class.loc[best_f1_idx, 'Model']",
        "print(f\"\\n\ud83c\udfc6 Mejor modelo por F1-Score: {best_model_name}\")",
        "print(f\"   F1-Score: {df_results_class.loc[best_f1_idx, 'F1-Score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizaci\u00f3n Comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Visualizaci\u00f3n de m\u00e9tricas",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))",
        "axes = axes.ravel()",
        "",
        "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'MCC', 'ROC-AUC']",
        "colors = ['steelblue', 'orange', 'green', 'red', 'purple', 'brown']",
        "",
        "for idx, (metric, color) in enumerate(zip(metrics_names, colors)):",
        "    ax = axes[idx]",
        "    ",
        "    values = df_results_class[metric].values",
        "    models = df_results_class['Model'].values",
        "    ",
        "    bars = ax.barh(models, values, color=color, alpha=0.7, edgecolor='black')",
        "    ax.set_xlabel(metric, fontsize=11)",
        "    ax.set_title(metric, fontweight='bold', fontsize=13)",
        "    ax.grid(alpha=0.3, axis='x')",
        "    ax.set_xlim(0, 1.05)",
        "    ",
        "    # A\u00f1adir valores",
        "    for bar, val in zip(bars, values):",
        "        if not np.isnan(val):",
        "            width = bar.get_width()",
        "            ax.text(width + 0.02, bar.get_y() + bar.get_height()/2,",
        "                   f'{val:.3f}', ha='left', va='center', fontsize=9, fontweight='bold')",
        "",
        "plt.suptitle('Comparaci\u00f3n de Clasificadores - Todas las M\u00e9tricas', ",
        "            fontsize=16, fontweight='bold')",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "# Parte 4: Mejores Pr\u00e1cticas en Validaci\u00f3n",
        "",
        "C\u00f3mo evitar errores comunes y obtener evaluaciones confiables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Data Leakage: El Enemigo Silencioso",
        "",
        "La fuga de informaci\u00f3n invalida la evaluaci\u00f3n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "print(\"=\"*80)",
        "print(\"EJEMPLO DE DATA LEAKAGE\")",
        "print(\"=\"*80)",
        "",
        "# Crear dataset simple",
        "X_leak, y_leak = make_classification(n_samples=200, n_features=10, random_state=42)",
        "",
        "print(f\"\\n--- INCORRECTO: Escalar antes de dividir ---\")",
        "# \u274c MAL: Escalar con todo el dataset",
        "scaler_wrong = StandardScaler()",
        "X_scaled_wrong = scaler_wrong.fit_transform(X_leak)",
        "",
        "# Luego dividir",
        "X_train_wrong, X_test_wrong, y_train_wrong, y_test_wrong = train_test_split(",
        "    X_scaled_wrong, y_leak, test_size=0.3, random_state=42",
        ")",
        "",
        "# Entrenar y evaluar",
        "model_wrong = LogisticRegression(max_iter=1000)",
        "model_wrong.fit(X_train_wrong, y_train_wrong)",
        "acc_wrong = model_wrong.score(X_test_wrong, y_test_wrong)",
        "",
        "print(f\"Accuracy (con leakage): {acc_wrong:.4f}\")",
        "print(f\"\u26a0\ufe0f  El scaler vio TODO el dataset \u2192 informaci\u00f3n del test filtr\u00f3 al train\")",
        "",
        "print(f\"\\n--- CORRECTO: Escalar solo con training ---\")",
        "# \u2705 BIEN: Primero dividir",
        "X_train_right, X_test_right, y_train_right, y_test_right = train_test_split(",
        "    X_leak, y_leak, test_size=0.3, random_state=42",
        ")",
        "",
        "# Luego escalar solo con training",
        "scaler_right = StandardScaler()",
        "X_train_scaled = scaler_right.fit_transform(X_train_right)",
        "X_test_scaled = scaler_right.transform(X_test_right)  # Solo transform, NO fit_transform",
        "",
        "# Entrenar y evaluar",
        "model_right = LogisticRegression(max_iter=1000)",
        "model_right.fit(X_train_scaled, y_train_right)",
        "acc_right = model_right.score(X_test_scaled, y_test_right)",
        "",
        "print(f\"Accuracy (sin leakage): {acc_right:.4f}\")",
        "print(f\"\u2713 El scaler solo vio training \u2192 evaluaci\u00f3n v\u00e1lida\")",
        "",
        "print(f\"\\nDiferencia: {acc_wrong - acc_right:.4f}\")",
        "print(f\"La evaluaci\u00f3n con leakage es artificialmente optimista!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Usando Pipelines para Evitar Leakage",
        "",
        "Los pipelines automatizan el flujo correcto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "from sklearn.pipeline import Pipeline",
        "",
        "# Pipeline correcto",
        "pipeline = Pipeline([",
        "    ('scaler', StandardScaler()),",
        "    ('classifier', LogisticRegression(max_iter=1000))",
        "])",
        "",
        "# Cross-validation con pipeline",
        "cv_scores = cross_val_score(pipeline, X_leak, y_leak, cv=5, scoring='accuracy')",
        "",
        "print(\"=\"*80)",
        "print(\"PIPELINE + CROSS-VALIDATION\")",
        "print(\"=\"*80)",
        "print(f\"\\nAccuracy por fold:\")",
        "for i, score in enumerate(cv_scores, 1):",
        "    print(f\"  Fold {i}: {score:.4f}\")",
        "",
        "print(f\"\\nMedia: {cv_scores.mean():.4f} \u00b1 {cv_scores.std():.4f}\")",
        "print(f\"\\n\u2713 El pipeline garantiza que el escalamiento se hace DENTRO de cada fold\")",
        "print(f\"\u2713 No hay leakage entre training y test en ning\u00fan fold\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Selecci\u00f3n de M\u00e9tricas Seg\u00fan Contexto",
        "",
        "No existe una m\u00e9trica universalmente superior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "print(\"=\"*80)",
        "print(\"GU\u00cdA DE SELECCI\u00d3N DE M\u00c9TRICAS\")",
        "print(\"=\"*80)",
        "",
        "print(\"\"\"",
        "\ud83d\udcca REGRESI\u00d3N:",
        "  M\u00e9trica    | Cu\u00e1ndo usar                        | Sensibilidad a outliers",
        "  -----------|------------------------------------|-----------------------",
        "  MAE        | Errores en escala original         | Baja (lineal)",
        "  MSE        | Penalizar errores grandes          | Alta (cuadr\u00e1tica)",
        "  RMSE       | MSE en escala original             | Alta (cuadr\u00e1tica)",
        "  R\u00b2         | Proporci\u00f3n de varianza explicada   | Media",
        "",
        "\ud83c\udfaf CLASIFICACI\u00d3N (Binaria):",
        "  Escenario                      | M\u00e9trica prioritaria",
        "  -------------------------------|--------------------",
        "  Clases balanceadas             | Accuracy, F1-Score",
        "  Clases desbalanceadas          | F1, MCC, ROC-AUC",
        "  Minimizar falsos positivos     | Precision",
        "  Minimizar falsos negativos     | Recall (Sensitivity)",
        "  Balance precision-recall       | F1-Score",
        "  Todas las celdas de CM         | MCC",
        "  Evaluar umbral variable        | ROC-AUC",
        "",
        "\u2695\ufe0f EJEMPLOS PR\u00c1CTICOS:",
        "  Problema                | Por qu\u00e9                           | M\u00e9trica",
        "  ------------------------|-----------------------------------|----------",
        "  Diagn\u00f3stico c\u00e1ncer      | FN son cr\u00edticos (no detectar)     | Recall",
        "  Detecci\u00f3n fraude        | FP son costosos (falsa alarma)    | Precision",
        "  Spam filtering          | Balance FP y FN                   | F1-Score",
        "  Clases muy desbalanceadas| Accuracy enga\u00f1osa                | MCC, F1",
        "  ",
        "\u26a0\ufe0f  IMPORTANTE:",
        "  \u2022 Accuracy es enga\u00f1osa con desbalance (puede ser alta prediciendo siempre la mayor\u00eda)",
        "  \u2022 Precision y Recall son opuestos (mejora de uno empeora el otro)",
        "  \u2022 F1 balancea Precision y Recall",
        "  \u2022 MCC es robusto con cualquier distribuci\u00f3n de clases",
        "  \u2022 ROC-AUC eval\u00faa todos los posibles umbrales",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "# Resumen y Conclusiones",
        "",
        "## \u2705 Lo que hemos aprendido",
        "",
        "### 1. Partici\u00f3n de Datos",
        "* **Hold-out simple**: R\u00e1pido pero con alta varianza",
        "* **k-Fold CV**: Est\u00e1ndar pr\u00e1ctico (k=5 t\u00edpicamente)",
        "* **Leave-One-Out**: Bajo sesgo, alta varianza, costoso",
        "* **Estratificaci\u00f3n**: Esencial con clases desbalanceadas",
        "",
        "### 2. M\u00e9tricas de Regresi\u00f3n",
        "* **MAE**: Robusto a outliers, escala original",
        "* **MSE**: Penaliza errores grandes, sensible a outliers",
        "* **RMSE**: MSE en escala original",
        "* **R\u00b2**: Proporci\u00f3n de varianza explicada",
        "",
        "### 3. M\u00e9tricas de Clasificaci\u00f3n",
        "* **Accuracy**: Simple pero enga\u00f1osa con desbalance",
        "* **Precision**: De los positivos predichos, cu\u00e1ntos son correctos",
        "* **Recall**: De los positivos reales, cu\u00e1ntos detectamos",
        "* **F1-Score**: Balance entre Precision y Recall",
        "* **ROC-AUC**: Desempe\u00f1o agregado en todos los umbrales",
        "* **MCC**: Robusto con cualquier distribuci\u00f3n de clases",
        "",
        "### 4. Mejores Pr\u00e1cticas",
        "* **Evitar data leakage**: Preprocesar DENTRO de cada fold",
        "* **Usar pipelines**: Automatizan el flujo correcto",
        "* **Reportar varianza**: El desempe\u00f1o no es un n\u00famero fijo",
        "* **Seleccionar m\u00e9trica apropiada**: Seg\u00fan el contexto del problema",
        "",
        "## \ud83c\udfaf Principios Clave",
        "",
        "1. **Sin partici\u00f3n no hay evaluaci\u00f3n v\u00e1lida**",
        "2. **El error en training es optimista**",
        "3. **Cross-validation reduce varianza**",
        "4. **La m\u00e9trica debe reflejar el objetivo del problema**",
        "5. **Data leakage invalida la evaluaci\u00f3n**",
        "",
        "## \ud83d\udcda Pr\u00f3ximos Pasos",
        "",
        "En m\u00f3dulos posteriores veremos:",
        "* Optimizaci\u00f3n de hiperpar\u00e1metros",
        "* Nested cross-validation",
        "* Evaluaci\u00f3n de modelos complejos",
        "* Interpretabilidad de resultados",
        "",
        "---",
        "",
        "**\u00a1Excelente trabajo!** \ud83c\udf89  ",
        "Has completado el m\u00f3dulo de validaci\u00f3n y evaluaci\u00f3n de modelos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}